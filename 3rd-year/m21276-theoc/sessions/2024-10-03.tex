\lecture{A1: Introduction to Languages}{13:00}{03/10/24}{Janka Chlebikova}

\section*{Languages}

In this context, a \textbf{language} is a set of symbols which can be combined to create a list of acceptable \textbf{strings}.
 There are then also rules which tell us how to combine these strings together, known as \textbf{grammars}. The 
 combination of an alphabet, list of valid strings and grammars is known as a language. There will be a formal definition
 later on.

\begin{definition*}{}{}
  An \textbf{Alphabet} is a finite, non-empty set of symbols.
\end{definition*}

For example, in the English language we would define the alphabet, $A$, as $A = \{a, b, c, d, \ldots, x, y, z\}$. These
 symbols can then be combined to create a \textbf{string}.

\begin{definition*}{}{}
  A \textbf{String} is a finite sequence of symbols from the alphabet of a language.
\end{definition*}

With the alphabet $A$, we could have strings such as `$cat$', `$dog$', `$antidisestablishmentarianism$', etc \textit{over} the
 alphabet. A string with no symbols, and therefore a length of zero, is known as the \textbf{empty string}, and is
 denoted by $\Lambda$ (capital lambda).

\begin{definition*}{}{}
  A \textbf{Language} over an alphabet (e.g. English over $A$) is a set of strings -- including $\Lambda$ -- made up of
   symbols from $A$ which are considered `valid'. They could be valid as per a set of rules, or could be arbitrary as
   in most spoken languages.
\end{definition*}

If we have an alphabet, $\Sigma$, then $\Sigma^*$ denotes the infinite set of all strings made up of symbols in $\Sigma$
 -- including $\Lambda$. Therefore, a language over $\Sigma$ is any subset of $\Sigma^*$.

\begin{example*}{}{}
  If $\Sigma = \{a, b\}$, then $\Sigma^* = \{\Lambda, a, b, aa, ab, ba, bb, \ldots\}$\\
  There are many languages which could be defined over this alphabet, but a few simple one are
  \begin{itemize}
    \item $\emptyset$ (The empty set)
    \item $\{\Lambda\}$ (The set containing an empty string)
    \item $\{a\}$ (The set containing $a$)
    \item The infinite set $\Sigma^* = \{\Lambda, a, aa, aaa, \ldots\}$
  \end{itemize}
\end{example*}

\section*{Combining Languages}

There are three common ways of combining two languages to create a new language -- union, intersection and product.

\subsection*{Union and Intersection}

Since languages are sets of strings, they can be combined as you usually would for any other set with the usual operations,
 union and intersection.

\begin{example*}{}{}
  If $L = \{aa, bb, cc\}$ and $M = \{cc, dd, ee\}$, then\\
  $L \cap M = \{cc\}$, and\\
  $L \cup M = \{aa, bb, cc, dd, ee\}$
\end{example*}

\subsection*{Product}

To combine two languages $L$ and $M$, we form the set of all \textbf{concatenations} of strings in $L$ with strings In
 $M$. This is known as the \textbf{product} of the two languages.

\begin{definition*}{}{}
  To \textbf{Concatenate} two strings is to juxtapose them such that a new string is made by appending the second string
   to the end of the first.
\end{definition*}

\begin{example*}{}{}
  If we concatenate the strings $ab$ and $ba$, the result would be $abba$.\\
  This can be represented using the function $\mathrm{cat}$, such as $\mathrm{cat}(ab, ba) = abba$
\end{example*}

With this definition of concatenation, we can say that the product of two languages, $L$ and $M$ would be $L \cdot M$,
 where $L \cdot M = \{\mathrm{cat}(s, t) : s \in L\ \mathrm{and}\ t \in M\}$

\begin{example*}{}{}
  If $L = \{a, b, c\}$ and $M = \{c, d, e\}$, then the product of the two languages, $L \cdot M$, is the language\\
  $L \cdot M = \{ac, ad, ae, bc, bd, be, cc, cd, ce\}$
\end{example*}

\section*{Further on Products}

It is simple to see that for any language, $L$, the following simple properties are true:
\begin{gather*}
  L \cdot \{\Lambda\} = \{\Lambda\} \cdot L = L\\
  L \cdot \emptyset = \emptyset \cdot L = \emptyset
\end{gather*}

\subsection*{Commutativity}

Aside from the above properties, the product of any two languages is \textbf{not} commutative, and therefore
\begin{equation*}
  L \cdot M \neq M \cdot L
\end{equation*}

\begin{example*}{}{}
  If $L = \{a, b\}$ and $M = \{b, c\}$, then the product $L \cdot M$ is the language
  \begin{equation*}
    L \cdot M = \{ab, ac, bb, bc\}
  \end{equation*}
  but the product $M \cdot L$ is the language
  \begin{equation*}
    M \cdot L = \{ba, bb, ca, cb\}
  \end{equation*}
  which are clearly not the same language, as the only common string is $bb$
\end{example*}

\subsection*{Associativity}

However, the product of any two languages is associative. This means that if we had any three languages, $L$, $M$ and
 $N$, then
\begin{equation*}
  L \cdot (M \cdot N) = (L \cdot M) \cdot N
\end{equation*}

\begin{example*}{}{}
  If we have the three languages $L = \{a, b\}$, $M = \{b, c\}$ and $N = \{c, d\}$, then
  \begin{align*}
    L \cdot (M \cdot N) &= L \cdot \{bc, bd, cc, cd\}\\
    &= \{abc, abd, acc, acd, bbc, bbd, bcc, bcd\}
  \end{align*}
  which is the same as
  \begin{align*}
    (L \cdot M) \cdot N &= \{ab, ac, bb, bc\} \cdot N\\
    &= \{abc, abd, acc, acd, bbc, bbd, bcc, bcd\}
  \end{align*}
\end{example*}

\section*{Powers of Languages}

If we have the language $L$, then the product $L \cdot L$ of the language is denoted by $L^2$. The product $L^n$ for
 every $n \in \mathbb{N}$ is defined as
\begin{align*}
  L^0 &= \{\Lambda\}\\
  L^n &= L \cdot L^{n-1}, \mathrm{if} n > 0
\end{align*}

\begin{example*}{}{}
  If $L = \{a, b\}$ then the first few powers of L are
  \begin{align*}
    L^0 &= \{\Lambda\}\\
    L^1 &= L = \{a, b\}\\
    L^2 &= L \cdot L = \{aa, ab, ba, bb\}\\
    L^3 &= L \cdot L^2 = \{aaa, aab, aba, abb, baa, bab, bba, bbb\}
  \end{align*}
\end{example*}

\section*{The Closure of a Language}

If $L$ is a language over $\Sigma$, then the \textbf{closure} of $L$ is the language denoted by $L^*$, and the
 \textbf{positive closure} is language denoted by $L^+$.

\begin{definition*}{}{}
  The \textbf{Closure} of the language $L$, $L^*$ is defined as
  \begin{equation*}
    L^* = L^0 \cup L^1 \cup L^2 \cup L^3 \cup \ldots
  \end{equation*}
  and so, if $L = \{a\}$ then
  \begin{align*}
    L^* &= \{\Lambda\} \cup \{a\} \cup \{aa\} \cup \{aaa\} \cup \ldots\\
    &= \{\Lambda, a, aa, aaa, \ldots\}
  \end{align*}
\end{definition*}

\begin{definition*}{}{}
  The \textbf{Positive Closure} the language $L$, $L^+$ is defined as
  \begin{equation*}
    L^+ = L^1 \cup L^2 \cup L^3 \cup L^4 \cup \ldots
  \end{equation*}
  and so, if $L = \{a\}$ then
  \begin{align*}
    L^+ &= \{a\} \cup \{aa\} \cup \{aaa\} \cup \{aaaa\} \cup \ldots\\
    &= \{a, aa, aaa, aaaa, \ldots\}
  \end{align*}
\end{definition*}

It then follows that $L^* = L^+ \cup \{\Lambda\}$, but it's not necessarily true that $L^+ = L^* - \{\Lambda\}$.

\begin{example*}{}{}
  If our alphabet is $\Sigma = \{a\}$ and our language is $L = \{\Lambda, a\}$, then
  \begin{equation*}
    L^+ = L^*
  \end{equation*}
\end{example*}

\subsection*{Properties of Closures}

Based upon these definitions, you can derive some interesting properties of closures.

\begin{example*}{}{}
  If $L$ and $M$ are languages over the alphabet $\Sigma$, then
  \begin{gather*}
    \{\Lambda\}^* = \emptyset^* = \{\Lambda\}\\
    L^* = L^* \cdot L^* = (L^*)^*\\
    \Lambda \in L \mathrm{\ if\ and\ only\ if\ } L^+ = L^*\\
    (L^* \cdot M^*)^* = (L^* \cup M^*)^* = (L \cup M)^*\\
    L \cdot (M \cdot L)^* = (L \cdot M)^* \cdot L
  \end{gather*}

  \textit{These will be explored more during the tutorial session for this week}
\end{example*}

\section*{The Closure of an Alphabet}

Going back to the definition of $\Sigma^*$ of the alphabet $\Sigma$, it lines up perfectly with the definition of a
 closure such that $\Sigma^*$ is the set of all strings over $\Sigma$. This means that there is a nice way to represent
 $\Sigma^*$ as follows
\begin{equation*}
  \Sigma^* = \Sigma^0 \cup \Sigma^1 \cup \Sigma^2 \cup \Sigma^3 \cup \ldots
\end{equation*}
From this, we can also see that $\Sigma^k$ denotes the set of all strings over $\Sigma$ whose length is $k$.

\lecture{A2: Grammars}{13:00}{03/10/24}{Janka Chlebikova}

As discussed previously, you can define a language over an alphabet as a set of arbitrary strings that are considered
 `valid', but you can also define a language using a \textbf{grammar}.

\begin{definition*}{}{}
  A \textbf{Grammar} is a set of rules used to define a language over an alphabet, by specifying the structure of valid
   strings in said language.
\end{definition*}

To describe the grammar of a language, two sets of symbols (alphabets) are required, terminals and non-terminals

\begin{definition*}{}{}
  \textbf{Terminal} symbols are those from which the actual strings which make up a language are derived, like the
   symbols discussed previously for a manually specified language. In the case of a spoken language, these would usually
   be lowercase letters, such as the latin alphabet used in English.
\end{definition*}

\begin{definition*}{}{}
  \textbf{Non-Terminal} symbols are `temporary' symbols (fully disjoint from the set of terminal symbols) used to define
   the grammar's replacement rules. These must all be replaced by terminals before a production can be considered a
   valid string in the language. These are usually represented by uppercase letters, or letters from an alphabet other
   than that of the language.
\end{definition*}

\section*{Productions}

Further to this, a grammar for the language $L$ over $\Sigma$ would typically consist of a set of productions (grammar
 rules) which allow you to produce the set of strings which make up $L$.

\begin{definition*}{}{}
  A \textbf{Production} is a rule which allows you to produce a string for a language. They are typically in the form
  \begin{equation*}
    \alpha \rightarrow \beta
  \end{equation*}
  where $\alpha$ is a string of symbols from the set of terminals ($\Sigma$) and $\beta$ is a string of symbols from the
   set of non-terminals.
\end{definition*}

You can read these rules in several ways -- $\alpha \rightarrow \beta$ could be read as;
\begin{itemize}
  \item replace $\alpha$ by $\beta$
  \item $\alpha$ produces $\beta$
  \item $\alpha$ rewrites as $\beta$
  \item $\alpha$ reduces to $\beta$
\end{itemize}

\section*{A Formal Definition}

Formally, a grammar is defined by the following properties
\begin{enumerate}
  \item An alphabet $T$ of terminal symbols (This is the same as the alphabet of the language defined by this grammar)
  \item An alphabet $N$ of non-terminal symbols
  \item A specific non-terminal symbol known as the \textbf{start symbol}, which is often $S$
  \item A finite set of productions in the form $\alpha \rightarrow \beta$ where $\alpha$ and $\beta$ are strings over
   the alphabet $N \cup T$
\end{enumerate}

Every grammar must have the special non-terminal symbol known as a start symbol, and it must also have at least one
 production in which the left side consists of only the start symbol.

\begin{example*}{}{}
  Let $G$ be a grammar defined by
  \begin{itemize}
    \item The set of terminals $T = \{a, b\}$
    \item A single non-terminal being the start symbol $S$
    \item The set of productions
    \begin{equation*}
      S \rightarrow \Lambda,\ S \rightarrow aSb
    \end{equation*}
     or for shorthand,
    \begin{equation*}
      S \rightarrow \Lambda \mid aSb
    \end{equation*}
  \end{itemize}
  To get the full set of strings which are valid for this grammar, we need to perform a \textbf{derivation}
\end{example*}

\subsection*{Derivations}

Starting from any production where the left side consists of only the start symbol, we can go through a step by step
 process to generate all strings belonging to the language described by a grammar.

\begin{example*}{}{}
  Using the grammar $G$ from the previous example, we could start with either of the two productions, since they both
   have only the start symbol $S$ on the left-hand side. This means that the first step of our process would give us
   $\Lambda$ and $aSb$.
\end{example*}

In this example, the string $aSb$ is a \textbf{sentential form} of the terminals $\{a, b\}$ and non-terminal $S$. From
 this point, to extend or generate any other strings, we need to perform a derivation.

\begin{definition*}{}{}
  If $x$ and $y$ are sentential forms, and $\alpha \rightarrow \beta$ is a production, then to replace $\alpha$ by
   $\beta$ in $x \alpha y$ is to \textbf{Derive} a new string. This is denoted by writing
  \begin{equation*}
    x \alpha y \Rightarrow x \beta y
  \end{equation*}
\end{definition*}

\begin{example*}{}{}
  Going back to the grammar $G$ again, since it contains the production $S \rightarrow aSb$, we could take our first
   step to generate the string $aSb$, then we can go another step further and derive $aaSbb$ from $aSb$, which means
  \begin{equation*}
    aSb \Rightarrow aaSbb
  \end{equation*}
  Since we can use this production again and again, we could derive that
  \begin{equation*}
    S \Rightarrow aSb \Rightarrow aaSbb \Rightarrow aaaSbbb \Rightarrow \ldots
  \end{equation*}
\end{example*}

To represent this multi-step process, we have the following symbols to show how the derivation was constructed
\begin{itemize}
  \item $\Rightarrow$ derives in a single step
  \item $\Rightarrow^+$ derives in one or more steps
  \item $\Rightarrow^*$ derives in zero or more steps
\end{itemize}

\begin{example*}{}{}
  Using the grammar $G$, we can show multiple derivations using these new symbols
  \begin{gather*}
    S \Rightarrow \Lambda, S \Rightarrow aSb, \therefore S \Rightarrow^* ab\\
    S \Rightarrow^* aaabbb\\
    S \Rightarrow^* aaaaaaSbbbbbb
  \end{gather*}
\end{example*}

\section*{What is $L(G)$?}

\begin{definition*}{}{}
  If $G$ is a grammar with the start symbol $S$ and the set of terminals $T$, then the language generated by $G$ is
   the set
  \begin{equation*}
    L(G) = \{s \mid s \in T^* \mathrm{\ and\ } S \Rightarrow^+ s\}
  \end{equation*}
  That is to say that it's the set of all strings containing only terminal symbols which can be derived from the start
   symbol with one or more steps.
\end{definition*}

\begin{example*}{}{}
  With the grammar $G$,
  \begin{equation*}
    L(G) = \{\Lambda, ab, aabb, aaabbb, aaaabbbb, \ldots\}
  \end{equation*}
\end{example*}

\section*{Infinite Languages}

Within an infinite language, there is no limit on the length of strings, and therefore also no limit on the number of
 steps needed to derive a string. If the grammar of a language has $n$ productions, then any derivation with $> n + 1$
 steps must use at least one production twice. Therefore, if a language is infinite, then a production or sequence of
 productions must be used repeatedly to construct the derivations of the grammar.

\begin{example*}{}{}
  The infinite language $\{a^n b \mid n \geq 0\}$ can be described by a grammar with the production $S \rightarrow b \mid aS$.
   To derive the string $a^n b$, you would apply the production $S \rightarrow aS$ $n$ times over and then finish the
   derivation with the production $S \rightarrow b$.
\end{example*}

With the production $S \rightarrow aS$, we can also say that ``If $S$ derives $w$, then it also derives $aw$''

\section*{Recursion and Indirect Recursion}

\begin{definition*}{}{}
  A production is \textbf{Recursive} if its entire left side is contained within the right side.
\end{definition*}
\begin{example*}{}{}
  The production $S \rightarrow aSb$ is recursive, since the sentential form it produces contains itself.
\end{example*}

\begin{definition*}{}{}
  A production is \textbf{Indirectly Recursive} if it is possible to derive a sentential form in two or more steps which
   contains the entire left side of the production.
\end{definition*}
\begin{example*}{}{}
  If a grammar contains the rules $S \rightarrow b \mid aA$ and $A \rightarrow c \mid bS$, then both productions are
   indirectly recursive, since
  \begin{gather*}
    S \Rightarrow aA \Rightarrow abS\\
    A \Rightarrow bS \Rightarrow baA
  \end{gather*}
\end{example*}

\subsection*{Recursive Grammars}

\begin{definition*}{}{}
  A grammar is \textbf{Recursive} if it contains either a recursive or indirectly recursive production.\ \textit{In order
   for a grammar to be infinite, it must first be recursive.}
\end{definition*}

\section*{Constructing Grammars}

We've seen previously how to derive a language from the definition of a grammar, but we also need to be able to construct
 a grammar to produce a language. It is often very difficult and sometimes impossible to write down a grammar for a
 given language, and there are often multiple grammars which form the exact same language.

\subsection*{Finite Languages}

In the case of a finite language, it is always possible to find a grammar which produces the language. This is because
 it is possible to simply make a grammar which contains a production for every string of the language, where
 $S \rightarrow w$ for every string $w$ in the language.

\begin{example*}{}{}
  The finite language $\{a, b, c, abc\}$ over the alphabet $\{a, b, c\}$ can be described by the grammar
  \begin{equation*}
    S \rightarrow a | b | c | abc
  \end{equation*}
\end{example*}

\subsection*{Infinite Languages}

However, in the case of an infinite language, there is no universal method that will always produce a valid grammar.
 This means it is much harder to find a valid grammar, and often requires \textbf{combining grammars}.

\begin{example*}{}{}
  A simple example of an infinite language would be $\{\Lambda, a, aa, aaa, \ldots\}$ which we can also write in the
   form $\{a^n : n \in \mathbb{N}\}$. We can then see that one grammar which describes this language is as follows;
  \begin{itemize}
    \item The set of terminals, $T = \{a\}$
    \item The non-terminal start symbol, $S$
    \item The productions $S \rightarrow \Lambda, S \rightarrow aS$
  \end{itemize}
\end{example*}

\section*{Combining Grammars}

Suppose we have two languages, $L$ and $M$ for which there are known grammars. There are a few simple rules we can use
 to create the grammars which describe the languages $L \cup M$, $L \cdot M$ and $L^*$.

To create this `composite' grammar, we can describe $L$ and $M$ with disjoint sets of non-terminals. If we have the
 start symbols of $L$ and $M$ as $A$ and $B$ respectively, i.e. $L : A \rightarrow \ldots$, $M : B \rightarrow \ldots$,
 we can then combine these as productions in another grammar to create the language.

\subsection*{Unions}

If we need to produce the union of two languages, $L \cup M$, we start with the two productions $S \rightarrow A \mid B$,
 followed by the productions which make up $L$ and $M$, using $A$ and $B$ as their respective start symbols.

\begin{example*}{}{}
  If we wanted to write the grammar that produces the language
  \begin{equation*}
    K = \{\Lambda, a, b, aa, bb, aaa, bbb, \ldots, a^n, b^n\}
  \end{equation*}
  we can realise that $K$ is the union of two different languages,
  \begin{align*}
    L &= \{a^n \mid n \in \mathbb{N}\}\\
    M &= \{b^n \mid n \in \mathbb{N}\}
  \end{align*}
  and so we can write a grammar for $K$ as
  \begin{itemize}
    \item $S \rightarrow A \mid B$ (Union rule)
    \item $A \rightarrow \Lambda \mid aA$ ($L$s grammar)
    \item $B \rightarrow \Lambda \mid bB$ ($M$s grammar)
  \end{itemize}
\end{example*}

\subsection*{Products}

Similarly, if we need to produce the the product of two languages, $L \cdot M$, we start with the production
 $S \rightarrow AB$, followed by the productions which make up $L$ and $M$, using $A$ and $B$ as their respective start
 symbols.

\begin{example*}{}{}
  If we wanted to write the grammar that produces the language
  \begin{equation*}
    K = \{\Lambda, a, b, aa, ab, aaa, bb, \ldots\}
  \end{equation*}
  we can realise that $K$ is the product of the two languages,
  \begin{align*}
    L &= \{a^n \mid n \in \mathbb{N}\}\\
    M &= \{b^n \mid n \in \mathbb{N}\}
  \end{align*}
  and so we can write a grammar for $K$ as
  \begin{itemize}
    \item $S \rightarrow AB$ (Product rule)
    \item $A \rightarrow \Lambda \mid aA$ ($L$s grammar)
    \item $B \rightarrow \Lambda \mid bB$ ($M$s grammar)
  \end{itemize}
\end{example*}

\subsection*{Closures}

And finally, if we need to produce the closure of a language, $L^*$, we start with the production $S \rightarrow AS \mid \Lambda$
 followed by the productions which make up $L$, using $A$ as its start symbol.

\begin{example*}{}{}
  If we wanted to write the grammar that produces the language $L^*$ where
  \begin{equation*}
    L = \{aa, bb\}
  \end{equation*}
  and so
  \begin{equation*}
    L^* = \{\Lambda, aa, bb, aaaa, aabb, bbbb, bbaa, \ldots\}
  \end{equation*}
  we can write the grammar for $L^*$ as
  \begin{itemize}
    \item $S \rightarrow AS \mid \Lambda$ (Closure rule)
    \item $A \rightarrow aa \mid bb$ ($L$s grammar)
  \end{itemize}
\end{example*}

\section*{Equivalent Grammars}

Any given language could have many different grammars which produce the exact same thing. This means that grammars are
 not unique. We can also use this to simplify grammars.

\begin{example*}{}{}
  Take the grammar from the previous example,
  \begin{gather*}
    S \rightarrow AS \mid \Lambda\\
    A \rightarrow aa \mid bb
  \end{gather*}
  If we replace $A$ in $S$ with the right side of $A$, $aa$, we get the production $S \rightarrow aaS$. We can then do
   the same with the other production to get $S \rightarrow bbS$. Therefore, we can write this grammar in a simplified
   form as
  \begin{equation*}
    S \rightarrow aaS \mid bbS \mid \Lambda
  \end{equation*}
\end{example*}